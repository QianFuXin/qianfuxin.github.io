<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>ollama使用小参数大模型实现简单的任务 | Y&amp;F</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="ollama使用小参数大模型实现简单的任务">
    <meta name="generator" content="Hugo 0.141.0">
    
    
    
      <meta name="robots" content="index, follow">
    
    
      <meta name="author" content = "钱甫新">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css" >



    

    
      

    

    

    
      <link rel="canonical" href="https://qianfuxin.gitHub.io/post/ollama%E4%BD%BF%E7%94%A8%E5%B0%8F%E5%8F%82%E6%95%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E4%BB%BB%E5%8A%A1/">
    

    <meta property="og:url" content="https://qianfuxin.gitHub.io/post/ollama%E4%BD%BF%E7%94%A8%E5%B0%8F%E5%8F%82%E6%95%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E4%BB%BB%E5%8A%A1/">
  <meta property="og:site_name" content="Y&F">
  <meta property="og:title" content="ollama使用小参数大模型实现简单的任务">
  <meta property="og:description" content="ollama使用小参数大模型实现简单的任务">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2025-05-24T10:58:08+00:00">
    <meta property="article:modified_time" content="2025-05-24T10:58:08+00:00">
    <meta property="article:tag" content="Ollama">
    <meta property="article:tag" content="大模型">

  <meta itemprop="name" content="ollama使用小参数大模型实现简单的任务">
  <meta itemprop="description" content="ollama使用小参数大模型实现简单的任务">
  <meta itemprop="datePublished" content="2025-05-24T10:58:08+00:00">
  <meta itemprop="dateModified" content="2025-05-24T10:58:08+00:00">
  <meta itemprop="wordCount" content="78">
  <meta itemprop="keywords" content="Ollama,大模型">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="ollama使用小参数大模型实现简单的任务">
  <meta name="twitter:description" content="ollama使用小参数大模型实现简单的任务">

      
    
	
  </head><body class="ma0 avenir bg-near-white production">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Y&amp;F
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="关于我 页">
              关于我
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="文章 页">
              文章
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        文章
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">ollama使用小参数大模型实现简单的任务</h1>
      
      <p class="tracked">
         <strong>钱甫新</strong>
      </p>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2025-05-24T10:58:08Z">五月 24, 2025</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h1 id="实际意义">实际意义</h1>
<p>很多场景下都是简单的任务，如果都用大参数大模型去处理，并发、资源、耗时都是问题。</p>
<p>所以对于某些简单的任务，可以让小参数大模型去做，不要精确率多高，只要有效，哪怕百分之十，配上程序的逻辑判断，都可以为生产做贡献。</p>
<h1 id="构建">构建</h1>
<h2 id="modelfile">modelfile</h2>
<pre tabindex="0"><code>FROM qwen3:0.6b
# 设置温度，较低的温度使输出更具确定性和一致性，适合分类任务
# 对于小模型，较低的温度有助于减少不相关或错误的输出
PARAMETER temperature 0.1

# 系统提示：明确告知模型其角色和任务，以及预期的输出类别
# 对于小模型，指令需要非常直接和清晰
SYSTEM 你是一个文本情绪分析助手。请将用户输入的文本分类为“积极”、“消极”或“中性”。

# 少样本提示：提供清晰的输入输出样例，帮助模型理解任务
# 样例要简单直接，符合小模型的理解能力
MESSAGE user 今天阳光明媚，我心情很好！
MESSAGE assistant 积极
MESSAGE user 我的项目失败了，感觉很难过。
MESSAGE assistant 消极
MESSAGE user 会议将在下午三点开始。
MESSAGE assistant 中性
MESSAGE user 这家餐厅的食物味道一般。
MESSAGE assistant 中性
</code></pre><h2 id="构建-1">构建</h2>
<p><code>ollama create emotion_cls -f ./Modelfile</code></p>
<h2 id="使用">使用</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>curl http://localhost:11434/api/generate -d <span style="color:#e6db74">&#39;{ &#34;model&#34;: &#34;emotion_cls&#34;,&#34;prompt&#34;:&#34;哈哈哈哈&#34;, &#34;stream&#34;: false}&#39;</span> | jq .
</span></span></code></pre></div><p>不使用思考模式</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>curl http://localhost:11434/api/generate -d <span style="color:#e6db74">&#39;{ &#34;model&#34;: &#34;emotion_cls&#34;,&#34;prompt&#34;:&#34;哈哈哈哈/no_think&#34;, &#34;stream&#34;: false}&#39;</span> | jq .
</span></span></code></pre></div><ul class="pa0">
  
   <li class="list di">
     <a href="/tags/ollama/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Ollama</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">大模型</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">相关內容</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/post/%E4%BD%BF%E7%94%A8vllm%E9%83%A8%E7%BD%B2qwen3/">使用vllm部署qwen3</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/%E5%AE%9E%E7%8E%B0rag%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/">实现rag的几种方式</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/%E9%80%9A%E8%BF%87%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E6%96%87%E4%BB%B6/">通过大模型自动生成代码文件</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/%E6%9C%AC%E5%9C%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9E%84%E5%BB%BA%E4%B8%AD%E6%96%87llama3_2%E5%B9%B6%E6%8F%90%E4%BE%9B%E7%AE%80%E5%8D%95%E5%AF%B9%E8%AF%9D%E9%A1%B5%E9%9D%A2/">本地自定义构建中文llama3_2并提供简单对话页面</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/pythongui%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B5%81%E5%BC%8F%E5%AF%B9%E8%AF%9D_whisper_ollama/">pythonGUI实现大模型流式对话_whisper_ollama</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/%E8%AF%B7%E6%B1%82openai%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%8E%A5%E5%8F%A3/">请求openai格式的接口</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://qianfuxin.gitHub.io/" >
    &copy;  Y&F 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
