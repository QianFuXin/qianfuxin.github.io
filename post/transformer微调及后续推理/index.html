<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>transformer微调及后续推理 | Y&amp;F</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="transformer微调及后续推理">
    <meta name="generator" content="Hugo 0.141.0">
    
    
    
      <meta name="robots" content="index, follow">
    
    
      <meta name="author" content = "钱甫新">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css" >



    

    
      

    

    

    
      <link rel="canonical" href="https://qianfuxin.gitHub.io/post/transformer%E5%BE%AE%E8%B0%83%E5%8F%8A%E5%90%8E%E7%BB%AD%E6%8E%A8%E7%90%86/">
    

    <meta property="og:url" content="https://qianfuxin.gitHub.io/post/transformer%E5%BE%AE%E8%B0%83%E5%8F%8A%E5%90%8E%E7%BB%AD%E6%8E%A8%E7%90%86/">
  <meta property="og:site_name" content="Y&F">
  <meta property="og:title" content="transformer微调及后续推理">
  <meta property="og:description" content="transformer微调及后续推理">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-09-28T10:58:08+00:00">
    <meta property="article:modified_time" content="2024-09-28T10:58:08+00:00">
    <meta property="article:tag" content="Transformer">
    <meta property="article:tag" content="微调">

  <meta itemprop="name" content="transformer微调及后续推理">
  <meta itemprop="description" content="transformer微调及后续推理">
  <meta itemprop="datePublished" content="2024-09-28T10:58:08+00:00">
  <meta itemprop="dateModified" content="2024-09-28T10:58:08+00:00">
  <meta itemprop="wordCount" content="97">
  <meta itemprop="keywords" content="Transformer,微调">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="transformer微调及后续推理">
  <meta name="twitter:description" content="transformer微调及后续推理">

      
    
	
  </head><body class="ma0 avenir bg-near-white production">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Y&amp;F
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="关于我 页">
              关于我
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="文章 页">
              文章
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        文章
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">transformer微调及后续推理</h1>
      
      <p class="tracked">
         <strong>钱甫新</strong>
      </p>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2024-09-28T10:58:08Z">九月 28, 2024</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h1 id="微调">微调</h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoModelForSequenceClassification
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;mps&#34;</span>)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> AutoModelForSequenceClassification<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;distilbert/distilbert-base-uncased&#34;</span>)<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> TrainingArguments
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args <span style="color:#f92672">=</span> TrainingArguments(
</span></span><span style="display:flex;"><span>    output_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;path/to/save/folder/&#34;</span>,
</span></span><span style="display:flex;"><span>    learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">2e-5</span>,
</span></span><span style="display:flex;"><span>    per_device_train_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>,
</span></span><span style="display:flex;"><span>    per_device_eval_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>,
</span></span><span style="display:flex;"><span>    num_train_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoTokenizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> AutoTokenizer<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;distilbert/distilbert-base-uncased&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> datasets <span style="color:#f92672">import</span> load_dataset
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> load_dataset(<span style="color:#e6db74">&#34;rotten_tomatoes&#34;</span>)  <span style="color:#75715e"># doctest: +IGNORE_RESULT</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tokenize_dataset</span>(dataset):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> tokenizer(dataset[<span style="color:#e6db74">&#34;text&#34;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> dataset<span style="color:#f92672">.</span>map(tokenize_dataset, batched<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> DataCollatorWithPadding
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data_collator <span style="color:#f92672">=</span> DataCollatorWithPadding(tokenizer<span style="color:#f92672">=</span>tokenizer)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> Trainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> Trainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>training_args,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>dataset[<span style="color:#e6db74">&#34;train&#34;</span>]<span style="color:#f92672">.</span>with_format(<span style="color:#e6db74">&#34;torch&#34;</span>, device<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;mps&#34;</span>),
</span></span><span style="display:flex;"><span>    eval_dataset<span style="color:#f92672">=</span>dataset[<span style="color:#e6db74">&#34;test&#34;</span>]<span style="color:#f92672">.</span>with_format(<span style="color:#e6db74">&#34;torch&#34;</span>, device<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;mps&#34;</span>),
</span></span><span style="display:flex;"><span>    tokenizer<span style="color:#f92672">=</span>tokenizer,
</span></span><span style="display:flex;"><span>    data_collator<span style="color:#f92672">=</span>data_collator,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>save_model(<span style="color:#e6db74">&#34;path/to/save/folder&#34;</span>)
</span></span></code></pre></div><h1 id="使用微调模型推理">使用微调模型推理</h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> pipeline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;mps&#34;</span>) <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>backends<span style="color:#f92672">.</span>mps<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cpu&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pipe <span style="color:#f92672">=</span> pipeline(<span style="color:#e6db74">&#34;fill-mask&#34;</span>, model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;path/to/save/folder&#34;</span>, device<span style="color:#f92672">=</span>device)
</span></span><span style="display:flex;"><span>print(pipe(<span style="color:#e6db74">&#34;The goal of life is [MASK].&#34;</span>))
</span></span></code></pre></div><ul class="pa0">
  
   <li class="list di">
     <a href="/tags/transformer/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Transformer</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%BE%AE%E8%B0%83/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">微调</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://qianfuxin.gitHub.io/" >
    &copy;  Y&F 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
