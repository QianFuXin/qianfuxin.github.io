<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Whisper on Y&amp;F</title>
    <link>https://qianfuxin.gitHub.io/tags/whisper/</link>
    <description>Recent content in Whisper on Y&amp;F</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 24 Sep 2024 10:58:08 +0000</lastBuildDate>
    <atom:link href="https://qianfuxin.gitHub.io/tags/whisper/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>pythonGUI实现大模型流式对话_whisper_ollama</title>
      <link>https://qianfuxin.gitHub.io/post/pythongui%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B5%81%E5%BC%8F%E5%AF%B9%E8%AF%9D_whisper_ollama/</link>
      <pubDate>Tue, 24 Sep 2024 10:58:08 +0000</pubDate>
      <guid>https://qianfuxin.gitHub.io/post/pythongui%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B5%81%E5%BC%8F%E5%AF%B9%E8%AF%9D_whisper_ollama/</guid>
      <description>&lt;h1 id=&#34;服务部署&#34;&gt;服务部署&lt;/h1&gt;&#xA;&lt;h2 id=&#34;部署whisper-api服务&#34;&gt;部署whisper api服务&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code&gt;version: &#39;3.8&#39;&#xA;&#xA;services:&#xA;  whisper-asr:&#xA;    image: onerahmet/openai-whisper-asr-webservice:latest&#xA;    container_name: whisper-asr-service&#xA;    ports:&#xA;      - &amp;quot;9099:9000&amp;quot;&#xA;    volumes:&#xA;      - /Users/qianfuxin/dc/whisper:/root/.cache/whisper&#xA;    environment:&#xA;      - ASR_MODEL=base&#xA;      - ASR_ENGINE=openai_whisper&#xA;    restart: unless-stopped&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;部署ollama&#34;&gt;部署ollama&lt;/h2&gt;&#xA;&lt;p&gt;见官网&lt;/p&gt;&#xA;&lt;h1 id=&#34;代码&#34;&gt;代码&lt;/h1&gt;&#xA;&lt;pre&gt;&lt;code&gt;import mimetypes&#xA;import os&#xA;import sys&#xA;from datetime import datetime&#xA;import socksio&#xA;import requests&#xA;from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QPushButton, QLabel, QTextEdit&#xA;import pyaudio&#xA;import wave&#xA;import threading&#xA;from langchain_core.messages import HumanMessage, SystemMessage&#xA;from langchain_core.output_parsers import StrOutputParser&#xA;from langchain_openai import ChatOpenAI&#xA;&#xA;&#xA;def transcribe_audio(file_path):&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;    Function to transcribe audio using the ASR service.&#xA;&#xA;    :param file_path: The full path to the audio file to be transcribed.&#xA;    :return: The response text from the ASR service.&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;    # Ensure the file exists&#xA;    if not os.path.isfile(file_path):&#xA;        raise FileNotFoundError(f&amp;quot;Audio file not found at: {file_path}&amp;quot;)&#xA;&#xA;    # Determine MIME type&#xA;    mime_type, _ = mimetypes.guess_type(file_path)&#xA;    if mime_type is None:&#xA;        raise ValueError(f&amp;quot;Unable to determine MIME type for file: {file_path}&amp;quot;)&#xA;&#xA;    # Extract file name&#xA;    file_name = os.path.basename(file_path)&#xA;&#xA;    url = &amp;quot;http://localhost:9099/asr&amp;quot;&#xA;    params = {&#xA;        &amp;quot;encode&amp;quot;: &amp;quot;true&amp;quot;,&#xA;        &amp;quot;task&amp;quot;: &amp;quot;transcribe&amp;quot;,&#xA;        &amp;quot;language&amp;quot;: &amp;quot;zh&amp;quot;,&#xA;        &amp;quot;initial_prompt&amp;quot;: &amp;quot;这是一段简体中文&amp;quot;,&#xA;        &amp;quot;word_timestamps&amp;quot;: &amp;quot;false&amp;quot;,&#xA;        &amp;quot;output&amp;quot;: &amp;quot;txt&amp;quot;&#xA;    }&#xA;    headers = {&#xA;        &amp;quot;accept&amp;quot;: &amp;quot;application/json&amp;quot;,&#xA;    }&#xA;&#xA;    # Open the audio file&#xA;    with open(file_path, &amp;quot;rb&amp;quot;) as audio_file:&#xA;        files = {&#xA;            &amp;quot;audio_file&amp;quot;: (file_name, audio_file, mime_type)&#xA;        }&#xA;&#xA;        # Send the POST request&#xA;        response = requests.post(url, headers=headers, params=params, files=files)&#xA;    return response.text&#xA;&#xA;&#xA;def get_model(base_url=&amp;quot;http://127.0.0.1:11434/v1&amp;quot;):&#xA;    &amp;quot;&amp;quot;&amp;quot;Get the AI model instance.&amp;quot;&amp;quot;&amp;quot;&#xA;    model = ChatOpenAI(&#xA;        api_key=&amp;quot;ollama&amp;quot;,&#xA;        model=&amp;quot;qwen2&amp;quot;,&#xA;        base_url=base_url&#xA;    )&#xA;    return model&#xA;&#xA;&#xA;class AudioRecorder:&#xA;    def __init__(self):&#xA;        self.p = pyaudio.PyAudio()&#xA;        self.stream = None&#xA;        self.frames = []&#xA;        self.device_index = None&#xA;        self.is_recording = False&#xA;        self.recording_thread = None&#xA;&#xA;    def list_input_devices(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;List available input devices.&amp;quot;&amp;quot;&amp;quot;&#xA;        device_list = []&#xA;        for i in range(self.p.get_device_count()):&#xA;            device_info = self.p.get_device_info_by_index(i)&#xA;            if device_info[&amp;quot;maxInputChannels&amp;quot;] &amp;gt; 0:&#xA;                device_list.append((i, device_info[&amp;quot;name&amp;quot;]))&#xA;        return device_list&#xA;&#xA;    def start_recording(self, device_index):&#xA;        &amp;quot;&amp;quot;&amp;quot;Start recording with the specified device.&amp;quot;&amp;quot;&amp;quot;&#xA;        self.device_index = device_index&#xA;        self.frames = []&#xA;        self.is_recording = True&#xA;&#xA;        self.stream = self.p.open(format=pyaudio.paInt16,&#xA;                                  channels=1,&#xA;                                  rate=44100,&#xA;                                  input=True,&#xA;                                  input_device_index=device_index,&#xA;                                  frames_per_buffer=1024)&#xA;&#xA;        self.recording_thread = threading.Thread(target=self.record)&#xA;        self.recording_thread.start()&#xA;&#xA;    def record(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;Record audio in a separate thread.&amp;quot;&amp;quot;&amp;quot;&#xA;        try:&#xA;            while self.is_recording:&#xA;                data = self.stream.read(1024, exception_on_overflow=False)&#xA;                self.frames.append(data)&#xA;        except IOError as e:&#xA;            print(f&amp;quot;Buffer overflow occurred: {e}&amp;quot;)&#xA;&#xA;    def stop_recording(self, filename):&#xA;        &amp;quot;&amp;quot;&amp;quot;Stop recording and save the file.&amp;quot;&amp;quot;&amp;quot;&#xA;        if self.is_recording:&#xA;            self.is_recording = False&#xA;            if self.recording_thread and self.recording_thread.is_alive():&#xA;                self.recording_thread.join()&#xA;&#xA;            if self.stream:&#xA;                self.stream.stop_stream()&#xA;                self.stream.close()&#xA;                self.stream = None&#xA;&#xA;            with wave.open(filename, &#39;wb&#39;) as wf:&#xA;                wf.setnchannels(1)&#xA;                wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))&#xA;                wf.setframerate(44100)&#xA;                wf.writeframes(b&#39;&#39;.join(self.frames))&#xA;&#xA;    def close(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;Close the PyAudio instance.&amp;quot;&amp;quot;&amp;quot;&#xA;        self.p.terminate()&#xA;&#xA;&#xA;class RecorderApp(QWidget):&#xA;    def __init__(self):&#xA;        super().__init__()&#xA;&#xA;        self.recorder = AudioRecorder()&#xA;        self.filename = None&#xA;        self.model = get_model()&#xA;        self.init_ui()&#xA;&#xA;    def init_ui(self):&#xA;        self.setWindowTitle(&amp;quot;实时语音识别与问答&amp;quot;)&#xA;        self.setGeometry(100, 100, 500, 400)&#xA;&#xA;        layout = QVBoxLayout()&#xA;&#xA;        # 开启录音按钮&#xA;        self.start_button = QPushButton(&amp;quot;开启录音&amp;quot;)&#xA;        self.start_button.clicked.connect(self.start_recording)&#xA;        layout.addWidget(self.start_button)&#xA;&#xA;        # 结束录音按钮&#xA;        self.stop_button = QPushButton(&amp;quot;结束录音&amp;quot;)&#xA;        self.stop_button.clicked.connect(self.stop_recording)&#xA;        self.stop_button.setEnabled(False)&#xA;        layout.addWidget(self.stop_button)&#xA;&#xA;        # 状态显示标签&#xA;        self.status_label = QLabel(&amp;quot;用户问题: &amp;quot;, self)&#xA;        layout.addWidget(self.status_label)&#xA;&#xA;        # 输出结果框&#xA;        self.output_box = QTextEdit(self)&#xA;        self.output_box.setReadOnly(True)&#xA;        layout.addWidget(self.output_box)&#xA;&#xA;        self.setLayout(layout)&#xA;&#xA;    def start_recording(self):&#xA;        device_index = 0  # For simplicity, we assume default device.&#xA;        start_time = datetime.now().strftime(&amp;quot;%Y%m%d_%H%M%S&amp;quot;)&#xA;        self.filename = f&amp;quot;{start_time}.wav&amp;quot;&#xA;&#xA;        self.recorder.start_recording(device_index)&#xA;        self.start_button.setEnabled(False)&#xA;        self.stop_button.setEnabled(True)&#xA;&#xA;    def stop_recording(self):&#xA;        self.recorder.stop_recording(self.filename)&#xA;        self.start_button.setEnabled(True)&#xA;        self.stop_button.setEnabled(False)&#xA;&#xA;        # 转录音频并生成回答&#xA;        transcription = transcribe_audio(self.filename)&#xA;        self.status_label.setText(f&amp;quot;用户问题: {transcription}&amp;quot;)&#xA;        self.generate_answer(transcription)&#xA;&#xA;    def generate_answer(self, transcription):&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        Send the transcription to the large model and display the streamed response.&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        QApplication.processEvents()&#xA;&#xA;        messages = [&#xA;            SystemMessage(&amp;quot;你是一个智能助手。&amp;quot;),&#xA;            HumanMessage(content=transcription)&#xA;        ]&#xA;        parser = StrOutputParser()&#xA;        chain = self.model | parser&#xA;&#xA;        response = &amp;quot;&amp;quot;&#xA;        for token in chain.stream(messages):&#xA;            response += token&#xA;            self.output_box.setText(response)&#xA;            QApplication.processEvents()&#xA;&#xA;&#xA;if __name__ == &amp;quot;__main__&amp;quot;:&#xA;    app = QApplication(sys.argv)&#xA;    window = RecorderApp()&#xA;    window.show()&#xA;    sys.exit(app.exec_())&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;仅仅实现asr&#34;&gt;仅仅实现ASR&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;import mimetypes&#xA;import os&#xA;import sys&#xA;from datetime import datetime&#xA;&#xA;import requests&#xA;from PyQt5.QtGui import QIcon&#xA;from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QPushButton, QLabel, QLineEdit, QComboBox, QMessageBox, \&#xA;    QSystemTrayIcon, QMenu, QAction&#xA;import pyaudio&#xA;import wave&#xA;import threading&#xA;&#xA;&#xA;def transcribe_audio(file_path):&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;    Function to transcribe audio using the ASR service.&#xA;&#xA;    :param file_path: The full path to the audio file to be transcribed.&#xA;    :return: The response text from the ASR service.&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;    # Ensure the file exists&#xA;    if not os.path.isfile(file_path):&#xA;        raise FileNotFoundError(f&amp;quot;Audio file not found at: {file_path}&amp;quot;)&#xA;&#xA;    # Determine MIME type&#xA;    mime_type, _ = mimetypes.guess_type(file_path)&#xA;    if mime_type is None:&#xA;        raise ValueError(f&amp;quot;Unable to determine MIME type for file: {file_path}&amp;quot;)&#xA;&#xA;    # Extract file name&#xA;    file_name = os.path.basename(file_path)&#xA;&#xA;    url = &amp;quot;http://localhost:9099/asr&amp;quot;&#xA;    params = {&#xA;        &amp;quot;encode&amp;quot;: &amp;quot;true&amp;quot;,&#xA;        &amp;quot;task&amp;quot;: &amp;quot;transcribe&amp;quot;,&#xA;        &amp;quot;language&amp;quot;: &amp;quot;zh&amp;quot;,&#xA;        &amp;quot;initial_prompt&amp;quot;: &amp;quot;这是一段简体中文&amp;quot;,&#xA;        &amp;quot;word_timestamps&amp;quot;: &amp;quot;false&amp;quot;,&#xA;        &amp;quot;output&amp;quot;: &amp;quot;txt&amp;quot;&#xA;    }&#xA;    headers = {&#xA;        &amp;quot;accept&amp;quot;: &amp;quot;application/json&amp;quot;,&#xA;    }&#xA;&#xA;    # Open the audio file&#xA;    with open(file_path, &amp;quot;rb&amp;quot;) as audio_file:&#xA;        files = {&#xA;            &amp;quot;audio_file&amp;quot;: (file_name, audio_file, mime_type)&#xA;        }&#xA;&#xA;        # Send the POST request&#xA;        response = requests.post(url, headers=headers, params=params, files=files)&#xA;&#xA;    return response.text&#xA;&#xA;&#xA;class AudioRecorder:&#xA;    def __init__(self):&#xA;        self.p = pyaudio.PyAudio()&#xA;        self.stream = None&#xA;        self.frames = []&#xA;        self.device_index = None&#xA;        self.is_recording = False&#xA;        self.recording_thread = None&#xA;&#xA;    def list_input_devices(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;列出所有可用的录音设备&amp;quot;&amp;quot;&amp;quot;&#xA;        device_list = []&#xA;        for i in range(self.p.get_device_count()):&#xA;            device_info = self.p.get_device_info_by_index(i)&#xA;            # 筛选出录音设备&#xA;            if device_info[&amp;quot;maxInputChannels&amp;quot;] &amp;gt; 0:&#xA;                device_list.append((i, device_info[&amp;quot;name&amp;quot;]))&#xA;        return device_list&#xA;&#xA;    def start_recording(self, device_index):&#xA;        &amp;quot;&amp;quot;&amp;quot;使用指定设备开始录音&amp;quot;&amp;quot;&amp;quot;&#xA;        self.device_index = device_index&#xA;        self.frames = []&#xA;        self.is_recording = True&#xA;&#xA;        self.stream = self.p.open(format=pyaudio.paInt16,&#xA;                                  channels=1,&#xA;                                  rate=44100,&#xA;                                  input=True,&#xA;                                  input_device_index=device_index,&#xA;                                  frames_per_buffer=1024)&#xA;&#xA;        # 启动录音线程&#xA;        self.recording_thread = threading.Thread(target=self.record)&#xA;        self.recording_thread.start()&#xA;&#xA;    def record(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;录音线程函数，用于捕获音频数据&amp;quot;&amp;quot;&amp;quot;&#xA;        try:&#xA;            while self.is_recording:&#xA;                data = self.stream.read(1024, exception_on_overflow=False)&#xA;                self.frames.append(data)&#xA;        except IOError as e:&#xA;            print(f&amp;quot;Buffer overflow occurred: {e}&amp;quot;)&#xA;&#xA;    def stop_recording(self, filename):&#xA;        &amp;quot;&amp;quot;&amp;quot;停止录音并保存文件&amp;quot;&amp;quot;&amp;quot;&#xA;        if self.is_recording:&#xA;            self.is_recording = False&#xA;            if self.recording_thread and self.recording_thread.is_alive():&#xA;                self.recording_thread.join()&#xA;&#xA;            if self.stream:&#xA;                self.stream.stop_stream()&#xA;                self.stream.close()&#xA;                self.stream = None&#xA;&#xA;            with wave.open(filename, &#39;wb&#39;) as wf:&#xA;                wf.setnchannels(1)&#xA;                wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))&#xA;                wf.setframerate(44100)&#xA;                wf.writeframes(b&#39;&#39;.join(self.frames))&#xA;&#xA;    def close(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;关闭 PyAudio 实例&amp;quot;&amp;quot;&amp;quot;&#xA;        self.p.terminate()&#xA;&#xA;&#xA;def resource_path(relative_path):&#xA;    &amp;quot;&amp;quot;&amp;quot;获取资源文件的绝对路径&amp;quot;&amp;quot;&amp;quot;&#xA;    if hasattr(sys, &#39;_MEIPASS&#39;):&#xA;        return os.path.join(sys._MEIPASS, relative_path)&#xA;    return os.path.join(os.path.abspath(&amp;quot;.&amp;quot;), relative_path)&#xA;&#xA;&#xA;class RecorderApp(QWidget):&#xA;    def __init__(self):&#xA;        super().__init__()&#xA;&#xA;        self.recorder = AudioRecorder()&#xA;        self.filename = None&#xA;&#xA;        self.init_ui()&#xA;&#xA;    def init_ui(self):&#xA;        self.setWindowTitle(&amp;quot;录音器&amp;quot;)&#xA;        self.setGeometry(100, 100, 400, 300)&#xA;&#xA;        # 创建系统托盘图标&#xA;        self.tray_icon = QSystemTrayIcon(self)&#xA;        self.tray_icon.setIcon(QIcon(resource_path(&amp;quot;icon.png&amp;quot;)))&#xA;&#xA;        # 创建托盘菜单&#xA;        tray_menu = QMenu()&#xA;&#xA;        # 添加显示窗口的选项&#xA;        show_action = QAction(&amp;quot;显示窗口&amp;quot;, self)&#xA;        show_action.triggered.connect(self.show)&#xA;        tray_menu.addAction(show_action)&#xA;&#xA;        # 添加退出的选项&#xA;        exit_action = QAction(&amp;quot;退出&amp;quot;, self)&#xA;        exit_action.triggered.connect(QApplication.instance().quit)&#xA;        tray_menu.addAction(exit_action)&#xA;&#xA;        # 将菜单添加到托盘图标&#xA;        self.tray_icon.setContextMenu(tray_menu)&#xA;&#xA;        # 设置点击双击托盘图标的动作&#xA;        self.tray_icon.activated.connect(self.on_tray_icon_activated)&#xA;&#xA;        # 显示托盘图标&#xA;        self.tray_icon.show()&#xA;&#xA;        layout = QVBoxLayout()&#xA;&#xA;        # 开启录音按钮&#xA;        self.start_button = QPushButton(&amp;quot;开启录音&amp;quot;)&#xA;        self.start_button.clicked.connect(self.start_recording)&#xA;        layout.addWidget(self.start_button)&#xA;&#xA;        # 结束录音按钮&#xA;        self.stop_button = QPushButton(&amp;quot;结束录音&amp;quot;)&#xA;        self.stop_button.clicked.connect(self.stop_recording)&#xA;        self.stop_button.setEnabled(False)&#xA;        layout.addWidget(self.stop_button)&#xA;&#xA;        # 设备选择下拉菜单&#xA;        self.device_selector = QComboBox(self)&#xA;        devices = self.recorder.list_input_devices()&#xA;        if devices:&#xA;            for index, name in devices:&#xA;                self.device_selector.addItem(name, index)&#xA;        else:&#xA;            QMessageBox.warning(self, &amp;quot;错误&amp;quot;, &amp;quot;未检测到录音设备&amp;quot;)&#xA;            self.start_button.setEnabled(False)&#xA;        layout.addWidget(self.device_selector)&#xA;&#xA;        # 状态显示标签&#xA;        self.status_label = QLabel(&amp;quot;状态: 未录音&amp;quot;, self)&#xA;        layout.addWidget(self.status_label)&#xA;&#xA;        self.setLayout(layout)&#xA;&#xA;    def closeEvent(self, event):&#xA;        &amp;quot;&amp;quot;&amp;quot;窗口关闭事件&amp;quot;&amp;quot;&amp;quot;&#xA;        if self.isVisible():  # 如果窗口可见，则最小化到托盘&#xA;            event.ignore()&#xA;            self.hide()&#xA;            self.tray_icon.showMessage(&#xA;                &amp;quot;应用最小化&amp;quot;, &amp;quot;程序已最小化到托盘&amp;quot;,&#xA;                QSystemTrayIcon.Information, 2000&#xA;            )&#xA;        else:  # 关闭应用时清理资源&#xA;            self.recorder.close()&#xA;            event.accept()&#xA;&#xA;    def on_tray_icon_activated(self, reason):&#xA;        &amp;quot;&amp;quot;&amp;quot;托盘图标激活事件&amp;quot;&amp;quot;&amp;quot;&#xA;        if reason == QSystemTrayIcon.DoubleClick:&#xA;            self.show()&#xA;&#xA;    def start_recording(self):&#xA;        device_index = self.device_selector.currentData()&#xA;        start_time = datetime.now().strftime(&amp;quot;%Y%m%d_%H%M%S&amp;quot;)&#xA;        self.filename = f&amp;quot;{start_time}.wav&amp;quot;&#xA;&#xA;        self.recorder.start_recording(device_index)&#xA;        self.status_label.setText(&amp;quot;状态: 录音中...&amp;quot;)&#xA;        self.start_button.setEnabled(False)&#xA;        self.stop_button.setEnabled(True)&#xA;&#xA;    def stop_recording(self):&#xA;        end_time = datetime.now().strftime(&amp;quot;%Y%m%d_%H%M%S&amp;quot;)&#xA;        self.filename = f&amp;quot;{self.filename[:-4]}-{end_time}.wav&amp;quot;  # 更新文件名&#xA;        self.recorder.stop_recording(self.filename)&#xA;        self.status_label.setText(f&amp;quot;状态: 录音已保存为 {self.filename}&amp;quot;)&#xA;        self.start_button.setEnabled(True)&#xA;        self.stop_button.setEnabled(False)&#xA;        self.status_label.setText(f&amp;quot;状态: 录音已保存为 {self.filename}\n录音内容：{transcribe_audio(self.filename)}&amp;quot;)&#xA;&#xA;&#xA;# 主程序入口&#xA;if __name__ == &amp;quot;__main__&amp;quot;:&#xA;    app = QApplication(sys.argv)&#xA;    window = RecorderApp()&#xA;    window.show()&#xA;    sys.exit(app.exec_())&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;    pyinstaller --onefile --windowed --noconfirm --add-data &amp;quot;icon.png;.&amp;quot; app.py&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
  </channel>
</rss>
